{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df15fd-dc37-46ba-864f-3b135bf32d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# the mean and std are the calculated statistics from cifar_10 dataset\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "# convert mean and std to 3-dimensional tensors for future operations\n",
    "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
    "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
    "\n",
    "epsilon = 8/255/std\n",
    "# TODO: iterative fgsm attack\n",
    "# alpha (step size) can be decided by yourself\n",
    "alpha = 0.8/255/std\n",
    "\n",
    "root = './data' # directory for storing benign images\n",
    "atk_root = './ifgsm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f5779-786e-4ae7-9354-0506463b2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
    "])\n",
    "\n",
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        '''\n",
    "        data_dir\n",
    "        ├── class_dir\n",
    "        │   ├── class1.png\n",
    "        │   ├── ...\n",
    "        │   ├── class20.png\n",
    "        '''\n",
    "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
    "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
    "            self.images += images\n",
    "            self.labels += ([i] * len(images))\n",
    "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.images[idx]))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    def __getname__(self):\n",
    "        return self.names\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "adv_set = AdvDataset(root, transform=transform)\n",
    "adv_names = adv_set.__getname__()\n",
    "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'number of images = {adv_set.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ef8b2-697a-47f8-b347-7d0eec0aaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the performance of model on benign images\n",
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yp = model(x)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e7d90-cd62-4531-a0e6-2bde0404413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yp = model(x)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d453f-46ef-492b-ad35-92e5fc28e3f8",
   "metadata": {},
   "source": [
    "# Attack Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c34dbc-f796-46de-b9c5-f66bcc46ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform fgsm attack\n",
    "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
    "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
    "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "    loss.backward() # calculate gradient\n",
    "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n",
    "    return x_adv\n",
    "\n",
    "# TODO: perform iterative fgsm attack\n",
    "# set alpha as the step size in Global Settings section\n",
    "# alpha and num_iter can be decided by yourself\n",
    "def ifgsm(models, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=100):\n",
    "    x_adv = x.detach().clone()\n",
    "    for i in range(num_iter):\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            x_adv = fgsm(model,x_adv,y,loss_fn,alpha)\n",
    "            x_adv = torch.min(torch.max(x_adv, x-epsilon),x+epsilon)\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a3a8a-1894-4f86-a10c-16c6516fb7e0",
   "metadata": {},
   "source": [
    "# Attack and Generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f07b88-90a9-4396-803c-725714e4b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform adversarial attack and generate adversarial examples\n",
    "def gen_adv_examples(models, loader, attack, loss_fn):\n",
    "    \n",
    "    adv_names = []\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(models, x, y, loss_fn) # obtain adversarial examples\n",
    "        yp = model(x_adv)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "        # store adversarial examples\n",
    "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
    "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
    "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
    "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
    "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
    "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
    "\n",
    "# create directory which stores adversarial examples\n",
    "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
    "    if os.path.exists(adv_dir) is not True:\n",
    "        _ = shutil.copytree(data_dir, adv_dir)\n",
    "    for example, name in zip(adv_examples, adv_names):\n",
    "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
    "        im.save(os.path.join(adv_dir, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89fb50f-2032-47ec-b8b2-a5592ea6e148",
   "metadata": {},
   "source": [
    "# Attack Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9cdb7-b0b9-4ca9-9f79-63d2e30dfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "models_name = ['resnet20_cifar10',\n",
    "          'resnet56_cifar10',\n",
    "          'resnet110_cifar10',\n",
    "          'resnet164bn_cifar10',\n",
    "          'resnet272bn_cifar10',\n",
    "          'resnet542bn_cifar10',\n",
    "          'resnet1001_cifar10',\n",
    "          'resnet1202_cifar10',\n",
    "          'preresnet20_cifar10',\n",
    "          'preresnet56_cifar10',\n",
    "          'preresnet110_cifar10',\n",
    "          'preresnet164bn_cifar10',\n",
    "          'preresnet272bn_cifar10',\n",
    "          'preresnet542bn_cifar10',\n",
    "          'preresnet1001_cifar10',\n",
    "          'preresnet1202_cifar10',\n",
    "          'seresnet20_cifar10',\n",
    "         'seresnet56_cifar10',\n",
    "         'seresnet110_cifar10',\n",
    "         'seresnet164bn_cifar10',\n",
    "         'seresnet272bn_cifar10',\n",
    "         'seresnet542bn_cifar10',\n",
    "         'sepreresnet20_cifar10']\n",
    "\n",
    "# models_name = ['resnet110_cifar10',\n",
    "#                'preresnet110_cifar10',\n",
    "#                'seresnet110_cifar10']\n",
    "\n",
    "models = [ptcv_get_model(model_name, pretrained=True).to(device) for model_name in models_name]\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
    "    print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486005a-f2bc-4209-a727-265f3200727a",
   "metadata": {},
   "source": [
    "# I-FGSM (generate ATK dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b798b-6346-4da2-ad0c-755a2a6bad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(models, adv_loader, ifgsm, loss_fn)\n",
    "print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n",
    "\n",
    "create_dir(root, 'ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0db6fb-2349-4f25-8c9b-1c1001d45230",
   "metadata": {},
   "source": [
    "# ATK dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe70a66-1eca-4396-9f0d-7ac258cc9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "atk_set = AdvDataset(atk_root, transform=transform)\n",
    "atk_names = atk_set.__getname__()\n",
    "atk_loader = DataLoader(atk_set, batch_size=batch_size, shuffle=False)\n",
    "print(f'number of images = {atk_set.__len__()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76126f15-d533-4cb8-8d7f-86386a1484bd",
   "metadata": {},
   "source": [
    "# Test on other model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d91a1-bcd8-4898-bb31-4c5873bfcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\n",
    "    other_acc, other_loss = epoch_benign(model, atk_loader, loss_fn)\n",
    "    print(f'acc = {other_acc:.5f}, loss = {other_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24347e68-53b6-414d-9491-5171b99d60e3",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd78f76-7853-4d13-bfb9-56ecb4b7773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "cnt = 0\n",
    "for i, cls_name in enumerate(classes):\n",
    "    path = f'{cls_name}/{cls_name}1.png'\n",
    "    # benign image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./data/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "    # adversarial image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./ifgsm/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0917516-8aee-4e33-82ab-903a68e71aa0",
   "metadata": {},
   "source": [
    "# output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d311b1b-260a-40b6-b701-c1e6df31675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ifgsm\n",
    "!tar zcvf ../ifgsm.tgz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609dccd-b90e-4f66-ac19-290438b7eba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
